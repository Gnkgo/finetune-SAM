{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98406,
     "status": "ok",
     "timestamp": 1711624699444,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "HKs4s9gmzgFR",
    "outputId": "65abf6ae-b989-461d-eebb-6a8f78c9d086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: segmentation-models-pytorch in /home/joanna/.local/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/joanna/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm in /home/joanna/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.2)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /home/joanna/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from segmentation-models-pytorch) (9.0.1)\n",
      "Requirement already satisfied: timm==0.9.2 in /home/joanna/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /home/joanna/.local/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: torch in /home/joanna/.local/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.2.2)\n",
      "Requirement already satisfied: munch in /home/joanna/.local/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (5.4.1)\n",
      "Requirement already satisfied: safetensors in /home/joanna/.local/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/joanna/.local/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.22.2)\n",
      "Requirement already satisfied: numpy in /home/joanna/.local/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.3)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: networkx in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n",
      "Requirement already satisfied: sympy in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/joanna/.local/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/joanna/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.4.99)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/joanna/.local/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.0)\n",
      "Requirement already satisfied: requests in /home/joanna/.local/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/joanna/.local/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/joanna/.local/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imgaug in /home/joanna/.local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (1.26.4)\n",
      "Requirement already satisfied: opencv-python in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (4.9.0.80)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from imgaug) (9.0.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (0.22.0)\n",
      "Requirement already satisfied: imageio in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (2.34.0)\n",
      "Requirement already satisfied: scipy in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (1.12.0)\n",
      "Requirement already satisfied: Shapely in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /home/joanna/.local/lib/python3.10/site-packages (from imgaug) (3.8.3)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/joanna/.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (0.3)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/joanna/.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (3.2.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/joanna/.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in /home/joanna/.local/lib/python3.10/site-packages (from scikit-image>=0.14.2->imgaug) (24.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/joanna/.local/lib/python3.10/site-packages (from matplotlib->imgaug) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/joanna/.local/lib/python3.10/site-packages (from matplotlib->imgaug) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/joanna/.local/lib/python3.10/site-packages (from matplotlib->imgaug) (4.50.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/joanna/.local/lib/python3.10/site-packages (from matplotlib->imgaug) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/joanna/.local/lib/python3.10/site-packages (from matplotlib->imgaug) (1.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U segmentation-models-pytorch\n",
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0zYpQh6YNdF"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35665,
     "status": "ok",
     "timestamp": 1711624735100,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "_hHIss0XbOJ0",
    "outputId": "5fe50835-3074-4ef0-cb5e-c7875309e0f8"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12812,
     "status": "ok",
     "timestamp": 1711624747887,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "zUyZBW7HwWzr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwteR3dQYNdH"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1711629363320,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "_RoVST0vYNdH",
    "outputId": "56c8e520-5d1b-4d97-d8fe-733ba4e09652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exist!\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_DRIVE = \"/home/joanna/scar-detection/\"\n",
    "IMG_DIR = GOOGLE_DRIVE + \"selected/\"\n",
    "MASK_DIR = GOOGLE_DRIVE + \"hand_masks/\"\n",
    "MODELS_DIR = GOOGLE_DRIVE + \"models/\"\n",
    "PREDICTION_DIR = GOOGLE_DRIVE + \"predictions/\"\n",
    "#BACKBONE = \"resnext50_32x4d\"\n",
    "BACKBONE = \"resnet34\"\n",
    "RESULT_DIR = GOOGLE_DRIVE + \"results/\"\n",
    "\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "\n",
    "MODEL_Title = \"WD-100-10-new-noval\"\n",
    "\n",
    "if os.path.exists(MODELS_DIR + MODEL_Title):\n",
    "    print(\"Already exist!\")\n",
    "else:\n",
    "    os.makedirs(MODELS_DIR + MODEL_Title)\n",
    "\n",
    "MODEL_Description = \"\"\"Scar-detection model trained over 100 epochs with batch size 10.\n",
    "Learning rate is kept at 0.001. No validation set.\"\"\"\n",
    "\n",
    "if MODEL_Description != \"\":\n",
    "    with open(MODELS_DIR + MODEL_Title + \"/description.txt\", \"w\") as f:\n",
    "        f.write(MODEL_Title + \"\\n\\n\" + MODEL_Description)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf0bav6-mKZq"
   },
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711624748580,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "-EDK21bZmIhj"
   },
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "    sometimes(iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "    iaa.LinearContrast((0.75, 1.5)),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05), per_channel=0.5),\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    iaa.Affine(\n",
    "       scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "       translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "       rotate=(-25, 25),\n",
    "       shear=(-8, 8)\n",
    "    )\n",
    "], random_order = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3Q1c0FvYNdI"
   },
   "source": [
    "## Dataset class for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711624748583,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "yn4kYUBKYNdI"
   },
   "outputs": [],
   "source": [
    "class WrinkleDataSet(Dataset):\n",
    "    def __init__(self, img_names, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.img_names = img_names\n",
    "        self.preprocess = smp.encoders.get_preprocessing_fn(BACKBONE, 'imagenet')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img = cv.imread(self.img_dir + img_name)\n",
    "        mask = cv.imread(self.mask_dir + img_name) / 255\n",
    "        mask = mask.astype(np.int8)\n",
    "        segmap = SegmentationMapsOnImage(mask, shape=img.shape)\n",
    "        img, segmap = seq(image=img, segmentation_maps=segmap)\n",
    "        img = self.preprocess(img)\n",
    "        segmap = segmap.draw(size=img.shape[:2])[0][:,:,0]\n",
    "        mask = np.where(segmap == 0, 0, 1)\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        img = img.float()\n",
    "        mask = torchvision.transforms.ToTensor()(mask)\n",
    "        mask = mask.float()\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKM7PxtxYNdJ"
   },
   "source": [
    "## Training and Validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711624748584,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "LwfKWgCQyhP2"
   },
   "outputs": [],
   "source": [
    "def train(model, device, preprocess, train_loader, optimizer, criterion, epoch, showLog=False):\n",
    "    train_loss = []\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    predictions = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (img, mask) in enumerate(train_loader):\n",
    "        img, mask = img.to(device), mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = criterion(pred, mask)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if showLog:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_idx, loss.item()))\n",
    "        pred = (torch.sigmoid(pred) > 0.5).float()\n",
    "        predictions.append(pred)\n",
    "        correct += (pred == mask).sum().item()\n",
    "        TP += torch.logical_and(pred == 1, mask == 1).sum()\n",
    "        FP += torch.logical_and(pred == 1, mask == 0).sum()\n",
    "        FN += torch.logical_and(pred == 0, mask == 1).sum()\n",
    "\n",
    "    train_loss = np.mean(train_loss)\n",
    "    epoch_acc = correct / len(train_loader.dataset)\n",
    "    epoch_precision = TP / (TP + FP)\n",
    "    epoch_recall = TP / (TP + FN)\n",
    "    return train_loss, epoch_acc, epoch_precision, epoch_recall\n",
    "\n",
    "def valid(model, device, preprocess, val_loader, criterion):\n",
    "    val_loss = []\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, mask in val_loader:\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, mask)\n",
    "            val_loss.append(loss.item())\n",
    "            pred = (torch.sigmoid(pred) > 0.5).float()\n",
    "            predictions.append(pred)\n",
    "            correct += (pred == mask).sum().item()\n",
    "            TP += torch.logical_and(pred == 1, mask == 1).sum()\n",
    "            FP += torch.logical_and(pred == 1, mask == 0).sum()\n",
    "            FN += torch.logical_and(pred == 0, mask == 1).sum()\n",
    "        val_loss = np.mean(val_loss)\n",
    "        epoch_acc = correct / len(val_loader.dataset)\n",
    "        epoch_precision = TP / (TP + FP)\n",
    "        epoch_recall = TP / (TP + FN)\n",
    "    return predictions, val_loss, epoch_acc, epoch_precision, epoch_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWbm7GZ7YNdJ"
   },
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 1                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "print(torch.cuda.memory_summary(1))\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1225042,
     "status": "ok",
     "timestamp": 1711628614049,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "DPFUyrPuYNdK",
    "outputId": "7e2f35f8-f5f3-4109-add0-98797bc8396c"
   },
   "outputs": [],
   "source": [
    "#!pip install light-the-torch\n",
    "#!ltt install torch torchvision\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Adjusted: DataParallel does not require specifying a device index here\n",
    "device = torch.device('cuda')\n",
    "\n",
    "image_names = [name for name in os.listdir(IMG_DIR) if name.endswith(\".png\")]\n",
    "train_names = image_names[:int(len(image_names)*0.8)]\n",
    "val_names = image_names[int(len(image_names)*0.8):]\n",
    "\n",
    "train_dataset = WrinkleDataSet(train_names, IMG_DIR, MASK_DIR)\n",
    "val_dataset = WrinkleDataSet(val_names, IMG_DIR, MASK_DIR)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "preprocess_fn = smp.encoders.get_preprocessing_fn(BACKBONE, 'imagenet')\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=BACKBONE,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = smp.losses.DiceLoss(mode=\"binary\")\n",
    "\n",
    "train_epoch_accuracy = []\n",
    "train_epoch_loss = []\n",
    "train_epoch_recall = []\n",
    "train_epoch_precision = []\n",
    "val_epoch_accuracy = []\n",
    "val_epoch_loss = []\n",
    "val_epoch_recall = []\n",
    "val_epoch_precision = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss, train_accuracy, train_precision, train_recall = train(model, device, preprocess_fn, train_dataloader, optimizer, criterion, epoch)\n",
    "\n",
    "    train_epoch_accuracy.append(train_accuracy)\n",
    "    train_epoch_loss.append(train_loss)\n",
    "    train_epoch_recall.append(train_recall)\n",
    "    train_epoch_precision.append(train_precision)\n",
    "    \n",
    "    predictions, val_loss, val_accuracy, val_recall, val_precision = valid(model, device, preprocess_fn, val_dataloader, criterion)\n",
    "\n",
    "    val_epoch_accuracy.append(val_accuracy)\n",
    "    val_epoch_loss.append(val_loss)\n",
    "    val_epoch_precision.append(val_precision)\n",
    "    val_epoch_recall.append(val_recall)\n",
    "\n",
    "    print(f\"{epoch+1} / {epochs}\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR + MODEL_Title + \"/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUUkfBTtYNdK"
   },
   "source": [
    "## Plotting of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3154,
     "status": "ok",
     "timestamp": 1711628617202,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "gC9LptiXVteS",
    "outputId": "a33ef0e6-15f5-4a1c-f89b-21730f493f38"
   },
   "outputs": [],
   "source": [
    "x_axis = np.arange(0, epoch+1)\n",
    "fig, axs = plt.subplots(4)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(15)\n",
    "fig.suptitle(\"Training performance\")\n",
    "axs[0].plot(x_axis, [item.cpu() for item in train_epoch_precision])\n",
    "axs[0].set_title(\"Training Precision\")\n",
    "axs[1].plot(x_axis, [item.cpu() for item in train_epoch_recall])\n",
    "axs[1].set_title(\"Training Recall\")\n",
    "axs[2].plot(x_axis, train_epoch_loss)\n",
    "axs[2].set_title(\"Training Loss\")\n",
    "axs[3].plot(x_axis, train_epoch_accuracy)\n",
    "axs[3].set_title(\"Training Accuracy \")\n",
    "fig.savefig(MODELS_DIR + MODEL_Title + \"/training.png\")\n",
    "\n",
    "fig, axs = plt.subplots(4)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(15)\n",
    "fig.suptitle(\"Validation performance\")\n",
    "axs[0].plot(x_axis, [item.cpu() for item in val_epoch_precision])\n",
    "axs[0].set_title(\"Validation Precision\")\n",
    "axs[1].plot(x_axis, [item.cpu() for item in val_epoch_recall])\n",
    "axs[1].set_title(\"Validation Recall\")\n",
    "axs[2].plot(x_axis, val_epoch_loss)\n",
    "axs[2].set_title(\"Validation Loss\")\n",
    "axs[3].plot(x_axis, val_epoch_accuracy)\n",
    "axs[3].set_title(\"Validation Accuracy \")\n",
    "fig.savefig(MODELS_DIR + MODEL_Title + \"/validation-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13462,
     "status": "ok",
     "timestamp": 1711628630663,
     "user": {
      "displayName": "G. L",
      "userId": "13854762890924209326"
     },
     "user_tz": -60
    },
    "id": "jeHlVMyoYNdL",
    "outputId": "dc514951-cca3-4a10-e6e3-b3c66e54950b"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(MODELS_DIR + MODEL_Title, 'zip', MODELS_DIR + MODEL_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IVEFRkPMoo7F",
    "outputId": "af96ec6a-ff1f-496c-e0f1-07d242dc2e8d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=BACKBONE,\n",
    "    encoder_weights=None,  # Ensure weights are not loaded, as you will load your trained weights below\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "model.load_state_dict(torch.load(MODELS_DIR + MODEL_Title + \"/model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing transformation for new images\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize to model input size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "import os\n",
    "\n",
    "def predict_and_display(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    input_image = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "\n",
    "    # Convert output to numpy array and post-process if needed\n",
    "    prediction = torch.sigmoid(output).cpu().numpy()\n",
    "    prediction = np.squeeze(prediction)  # Remove batch dimension if present\n",
    "\n",
    "    # Display original image and predicted mask\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(prediction, cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Save the predicted mask image in the results directory\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    save_path = os.path.join(RESULT_DIR, f\"{image_name}_predicted_mask.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "for i in range(24):\n",
    "  image_path = PREDICTION_DIR + str(i) + \".png\"\n",
    "  predict_and_display(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
